---
title: 011-10 김예은 (과제-08)
layout: home
nav_order: 10
parent: 과제-08 기말과제 초고 작성하기
permalink: /asmt-08/011-10
---

# (초고) 과제-08 기말과제 초고 작성하기 011-10 김예은 

# 제목:알고리즘 기반 정보 추천 시스템과 정치적 양극화: 선택적 노출 구조의 심화 메커니즘

## 서론

인터넷의 급격한 발전은 현대 사회의 정치 지형에 지대한 영향을 미쳐 왔다. 1990년대 중반 상용화된 인터넷은 정보의 유통과 접근성을 비약적으로 향상시켰으며, 개인과 집단 간의 소통 방식을 혁신적으로 변화시켰다. 이러한 기술적 혁신은 단순한 정보 전달의 차원을 넘어 정치적 담론의 형성, 여론의 동원, 그리고 집단 간의 인식 구조를 재편하는 데까지 그 영향을 미쳤다. 이러한 변화는 정보 선택의 자유를 확대하고, 개인의 관심사와 선호에 기반한 자율적 정보 소비를 가능하게 했다는 긍정적 평가를 받기도 한다. 그러나 다른 한편에서는 인터넷의 활성화가 오히려 사회 내 이념적 분열과 정치적 양극화를 심화시킨다는 우려도 제기되고 있다.  이러한 문제의식은 정치학, 사회학, 커뮤니케이션학 등 다양한 학문 분야에서 중요한 연구 주제로 다루어지고 있다.
정치적 양극화란 정치적 입장의 스펙트럼이 극단화되어, 사회 내 상반된 의견 간의 합의 가능성이 점점 줄어들고 대립이 격화되는 현상을 말한다. 양극화의 심화는 민주주의의 작동 원리를 위협하고 사회적 갈등을 증폭시키는 요인이 되기 때문에, 이를 설명하고 이해하는 것은 학문적·실천적 측면에서 모두 중요한 과제이다. 여기서 알고리즘은 개인의 선호에 맞춘 정보 제공을 통해 표현의 자유를 실현하는 한편, 동시에 정보 다양성을 축소하고 이념 간 적대감을 심화시키는 구조적 기제로 작동할 수 있는 잠재성을 내포하고 있다는 점이 딜레마가 된다.
본 논문은 이러한 딜레마를 해소하고자 먼저 알고리즘 기반 추천 시스템이 사용자의 선택적 노출 경향과 상호작용하여 정치적 양극화를 촉진하는 구조를 형성한다는 점을 밝힌다. 특히 알고리즘은 사용자 개인의 성향을 실시간으로 학습하고 반영하여 유사한 성향의 콘텐츠를 반복적으로 노출함으로써 필터 버블을 형성하며(Spohr, 2017), 이는 반대 의견과의 접촉 가능성을 구조적으로 제한하는 결과를 초래한다. 또한 사용자의 선택적 노출 경향 자체가 반대 의견을 회피하는 방향으로 작동하며, 이는 결과적으로 이념적 고착을 강화한다는 점이 Bail et al.(2018)의 실험 연구에서 확인된 바 있다. Bail 등은 트위터 사용자들을 대상으로 반대 진영의 트윗을 강제로 노출시키는 실험을 수행한 결과, 오히려 사용자의 기존 정치 성향이 강화되는 역효과(backfire effect)가 나타났음을 보여주었다. 나아가 알고리즘 기반 정보 소비 구조는 허위 정보의 확산을 가속화하며(Tucker et al., 2018), 특히 감정적으로 자극적인 콘텐츠가 우선적으로 노출되는 소셜미디어의 특성과 결합하여(AAPA 콘텐츠, Piccardi et al., 2024) 정치적 적대감과 사회적 분열을 증폭시킨다. 반면, 알고리즘 기반 정보 추천이 오히려 정보 선택의 자유와 다양성을 보장한다는 입장도 존재한다. Gentzkow & Shapiro(2011)는 1,000만 명의 온라인 뉴스 소비 데이터를 분석한 연구에서 오프라인 미디어(신문, 케이블 뉴스)보다 온라인 뉴스 환경에서의 이념적 분리가 오히려 낮게 나타났음을 보고하며, 알고리즘이 필터 버블을 만드는 주체라기보다 인간의 본질적인 선택적 노출 경향이 양극화를 설명하는 더 중요한 변수라고 주장하였다. Barbera(2015) 역시 대규모 트위터 데이터를 분석하여 소셜미디어 사용이 필연적으로 양극화를 유발하지 않으며, 오히려 다양한 정치적 의견과의 접촉 기회를 제공할 가능성도 있음을 시사하였다. 이러한 연구들은 알고리즘이 정보 소비를 더욱 폭넓고 다양한 방향으로 확장시킬 가능성을 지닌다는 점에서, 기술 자체를 양극화의 주범으로 지목하는 해석에 신중해야 한다는 입장을 제시한다.
따라서 본 연구는 인터넷의 알고리즘 기반 정보 소비 구조가 정치적 양극화를 심화시키는 구조적 요인으로 작용함을 규명하고자 한다. 이를 위해 본론에서는 다음과 같은 논증 구조를 따른다. [1] 먼저 알고리즘이 사용자의 기존 성향을 강화하는 방식으로 필터 버블과 정보 편향을 형성하며, 이로 인해 반대 의견과의 접촉 기회를 구조적으로 차단한다는 점을 Spohr(2017), Pariser(2011) 등의 논의를 통해 검토한다. [2] 이어서 사용자의 선택적 노출 경향이 반대 의견 회피를 강화하고 이념적 고착을 심화한다는 점을 Bail et al.(2018)의 실험 연구 및 Sunstein(2007)의 ‘이념적 게토’ 개념을 바탕으로 분석한다. [3] 나아가 이러한 알고리즘-선택성 구조가 허위정보의 확산을 촉진하고 감정적 양극화를 증폭시키는 기제로 작용함을 Tucker et al.(2018), Piccardi et al.(2024)의 사례 분석을 통해 논의한다. [4] 반론으로서 Gentzkow & Shapiro(2011), Barbera(2015) 등의 연구를 검토하며, 알고리즘이 필터 버블을 조장하지 않으며 오히려 다양한 정치적 의견에 대한 접촉 기회를 제공할 수 있다는 입장을 비판적으로 평가한다. [5] 이를 통해 인터넷 알고리즘이 선택적 노출 경향을 구조적으로 심화시키며 정치적 양극화를 촉진한다는 본 연구의 주장을 정당화하고, 알고리즘 기반 정보 소비 구조가 자율성의 실현을 방해하며 사회적 분열을 가속화하는 구조적 문제를 드러내고자 한다.

## 본론

### ­­1. 알고리즘 기반 정보 추천 시스템의 선택적 노출 메커니즘

알고리즘 기반 정보 추천 시스템은 사용자 개개인의 관심사, 클릭 기록, 체류 시간과 같은 데이터를 분석하여 개인화된 콘텐츠를 제공하는 방식을 취한다. 이 과정에서 선택적 노출(selective exposure)이라는 심리적 경향이 중요한 역할을 한다. 선택적 노출은 사용자가 자신과 일치하는 정보에만 주목하고, 반대 의견이나 이질적인 정보는 의도적으로 배제하는 경향을 의미한다(Sunstein, 2007). 이때 알고리즘은 사용자의 이러한 선택적 경향을 학습하고, 더 많은 유사한 정보를 반복적으로 추천함으로써 정보의 다양성을 제한하는 ‘필터 버블(filter bubble)’을 형성한다. 필터 버블은 사용자가 보고 싶은 정보만을 접하게 되는 정보의 거품 구조를 의미하며(Pariser, 2011), 알고리즘과 사용자 성향의 결합으로 인해 생성된다.
Spohr(2017)는 이 필터 버블의 형성을 구조적으로 설명한다. 그는 알고리즘이 사용자의 선호 데이터를 실시간으로 추적하고, 이를 기반으로 과거 선택과 유사한 콘텐츠를 우선적으로 노출시킴으로써 정보의 편향적 분포를 강화하는 메커니즘을 강조한다. 즉, 사용자가 스스로 정보를 선택하는 것처럼 보이지만, 실상은 알고리즘이 제한된 선택지를 미리 제시함으로써 사용자 경험을 사실상 유도하고 있는 것이다(Spohr, 2017: 150).

알고리즘은 사용자의 클릭 패턴, 좋아요, 댓글, 시청 시간 등을 분석하여 사용자가 선호할 만한 콘텐츠를 예측하고 추천한다. 이때 추천된 정보는 주로 사용자의 기존 성향과 일치하는 내용으로 채워지며, 이는 사용자가 반대 견해에 접촉할 기회를 점점 줄어들게 만든다. Spohr(2017)의 연구에 따르면, 2016년 미국 대선 기간 동안 가짜뉴스나 선동적인 정치 콘텐츠가 알고리즘에 의해 실제 뉴스보다 더 많은 확산력을 보였으며, 이는 사용자의 기존 성향을 강화하는 방향으로 작동했다. Pariser(2011) 역시 필터 버블이 정보를 개인화하는 과정에서 정보 다양성을 감소시키고, 사용자가 반대 의견에 노출될 기회를 줄이며, 결과적으로 정치적 양극화를 심화시킬 수 있음을 경고했다.
이러한 알고리즘의 선택적 노출 강화 효과는 단순히 정보량의 축소 문제가 아니다. 사용자가 소비하는 정보의 질적 구성 자체가 왜곡되며, 정치적으로 편향된 정보만이 사용자 환경에 축적되기 때문에, 정보의 폐쇄성은 한층 더 심화된다(Spohr, 2017: 153). 즉, 알고리즘 기반 추천 시스템은 정보 선택권을 보장하는 듯 보이지만, 실상은 사용자의 성향을 강화하며 정보 환경을 점점 단일화하는 방향으로 작동한다.

### 2. 사용자의 선택적 노출 경향과 반대 의견 회피의 상관관계

선택적 노출은 사용자가 자신의 기존 신념이나 성향과 일치하는 정보만 선택해 소비하는 심리적 메커니즘이다(Sunstein, 2007). 이러한 경향은 반대 의견 접촉의 감소와 직접적으로 연결된다. Sunstein(2007)은 이를 ‘이념적 게토(ideological ghetto)’라는 개념으로 설명하며, 사용자가 선택적으로 유사한 성향의 정보만 소비하는 상황에서는 이념 간 대화의 기회가 줄어들고, 반대 의견에 대한 노출 자체가 불편한 경험으로 인식되며 회피되기 쉽다고 지적한다. 즉, 선택적 노출은 단순한 취향의 문제가 아니라, 이념적 편향을 강화하고, 반대 의견 접촉의 가능성을 구조적으로 차단하는 심리적 토대를 제공한다.

이러한 선택적 노출 경향과 반대 의견 회피의 상관관계를 실증적으로 보여주는 연구로 Bail et al.(2018)의 실험이 있다. Bail et al.(2018)은 미국 내 SNS 사용자들을 대상으로 실험을 진행해, 참가자들을 인위적으로 반대 진영의 트윗에 노출시킨 결과를 분석했다. 실험 결과는 예상과 달리, 참가자들이 반대 진영의 의견을 접한 이후, 오히려 자신의 기존 정치 성향을 더욱 강화하는 경향을 보였음을 보여주었다(Bail et al., 2018: 922). 이는 반대 견해 노출이 이념적 균형을 회복하기보다, 오히려 사용자의 기존 성향에 대한 확증편향을 자극해 이념적 고착을 강화하는 효과를 가진다는 점을 입증한다.
즉, 사용자의 선택적 노출 경향은 단순히 반대 의견의 무관심이나 무지에서 비롯된 것이 아니라, 반대 의견을 회피하고 거부하며 자신이 속한 진영의 논리와 감정을 더욱 굳건히 하는 메커니즘으로 작용한다. Bail et al.(2018)의 연구는 선택적 노출과 반대 의견 회피가 서로 분리된 요소가 아니라, 심리적-인지적 메커니즘 상에서 서로 긴밀하게 연결되어 있음을 실증적으로 보여준다.

### 3. 알고리즘-선택성 구조의 정보 환경 왜곡 효과

알고리즘과 선택적 노출이 결합된 정보 환경에서는 특히 허위 정보와 감정적 콘텐츠가 빠르게 확산되는 특징이 나타난다. 알고리즘은 클릭 수, 공유 수, 댓글 수 등 사용자의 반응 지표를 기반으로 콘텐츠의 우선순위를 결정하는데, 이때 사실 여부보다 자극성이나 감정적 반응을 유발하는 요소가 더 큰 가중치를 받는다(Spohr, 2017). Tucker et al.(2018)은 허위 정보가 실제 뉴스보다 더 높은 확산력을 보이는 이유를 설명하며, 알고리즘이 정보의 진위를 평가하기보다는 사용자의 반응을 기준으로 콘텐츠 노출을 결정하기 때문에, 허위 정보와 자극적인 콘텐츠가 더 많은 사람들에게 도달한다고 분석한다. 또한 Piccardi et al.(2024)의 연구는 반민주적 태도와 정당 간 적대감을 담은 AAPA(anti-democratic, affect-laden, partisan, antagonistic) 콘텐츠가 사용자 감정을 자극하며, 알고리즘과 결합해 정보 환경을 왜곡하는 사례를 실험적으로 보여준다.

허위 정보와 감정적 콘텐츠의 확산은 단순히 잘못된 정보의 유통 문제를 넘어, 정치적 양극화의 심화에 직접적으로 기여한다. Tucker et al.(2018)은 허위 정보의 확산이 사회적 불신과 감정적 적대감을 유발하여 사회 통합을 저해한다고 지적하며, 이는 곧 정치적 양극화의 주요 동력으로 작동한다고 설명한다. Piccardi et al.(2024) 역시 AAPA 콘텐츠가 정치적 반대 세력에 대한 적대감을 증폭시키며, 이는 단순한 의견 대립을 넘어 감정적 분노와 공격성으로 이어지는 경향이 있음을 실험을 통해 확인했다. 이러한 경향은 단일 사건이 아닌 반복적인 알고리즘-선택성 상호작용을 통해 누적되며, 정치적 양극화를 심화시키는 구조적 요인으로 작용한다.

### 예상반론: 선택적 노출 경향은 알고리즘 이전에도 존재한 인간의 보편적 특성이다

알고리즘이 사용자들의 기존 성향을 강화한다는 주장은 과연 정당한가? 이에 대한 반론은 Gentzkow와 Shapiro(2011)의 연구를 통해 제기된다. 이들은 1,000만 명 이상의 온라인 뉴스 소비 데이터를 분석하여, 온라인 뉴스 환경보다 오히려 오프라인 미디어(케이블 뉴스, 인쇄물 등)에서 이념적 분리 지수가 더 높게 나타난다는 사실을 보였다. 이러한 결과는 선택적 노출 경향이 기술적 구조 이전에 이미 인간의 인지적 습성에 뿌리내려 있다는 점을 시사한다. 즉, 사람들은 원래부터 자신과 비슷한 성향의 정보를 선택적으로 소비해왔으며, 이는 알고리즘의 존재 여부와 상관없이 발생하는 현상이라는 것이다. 따라서 알고리즘이 양극화를 구조적으로 촉진한다는 주장은, 기술 자체에 과도한 책임을 전가하는 주장일 뿐이며, 본질적으로는 인간의 선택적 노출 경향과 오프라인 미디어 환경의 제약에서 기인하는 현상일 수 있다.

### 재반박: 알고리즘은 선택적 노출의 경향을 근본적으로 구조화하고 심화시키는 기제다

이 반론은 인간의 선택적 노출 경향을 설명하지만, 그 경향이 어떻게 강화되고, 질적으로 변화하며, 구조적으로 고착되는지에 대해서는 설명하지 못한다. 선택적 노출 경향은 인간의 인지적 성향으로서 분명히 존재한다. 그러나 이 성향은 본래 정보 접근의 물리적 한계, 시간적 제약, 사회적 맥락 등 다양한 장벽 속에서 제한적으로 발현되었으며, 이로 인해 그 파급력 또한 상대적으로 미미했다. 알고리즘은 이러한 인간의 선택 성향을 단순히 반영하는 것이 아니라, 이를 가속화하고 증폭하며, 사회 전반에 걸쳐 체계적 구조로 재편하는 역할을 수행한다.
첫째, 알고리즘은 선택적 노출의 속도를 비약적으로 증대시킨다. 오프라인 미디어 환경에서는 사용자가 다양한 정보를 찾아보고, 비교하며, 선택하는 과정에 시간과 노력이 요구되었다. 반면, 알고리즘은 사용자의 클릭, 체류 시간, 반응 등을 실시간으로 분석하여 즉각적으로 '사용자가 좋아할 만한' 정보를 제공한다. 이 과정은 정보 탐색의 과정을 생략하고, 사용자가 반대 의견에 노출될 기회를 의식조차 하기 전에 제거해버린다.
둘째, 알고리즘은 선택적 노출의 강도를 심화한다. Spohr(2017)는 알고리즘이 클릭과 주목이라는 경제적 가치에 최적화되며, 사용자에게 비슷한 성향의 정보만을 반복적으로 제공함으로써 필터 버블을 강화한다고 지적한다. 이는 단순히 사용자가 좋아하는 정보만 모아주는 차원이 아니라, '다른 관점' 자체를 점점 더 희미하게 만들고, 나아가 반대 의견에 대한 정서적 거부감과 적대감을 키우는 효과를 낳는다.
셋째, 알고리즘은 선택적 노출의 규모를 사회 전체 차원으로 확장한다. 오프라인 미디어에서의 선택은 개인의 작은 습관에 국한되었지만, 알고리즘은 수많은 사용자들에게 동시적으로 맞춤형 정보를 제공하며, 이로써 집단 차원의 이념적 격차를 확대하고 사회 전체의 인식 지형을 변화시킨다. 개별 사용자의 성향이 단순히 개인 차원의 기호를 넘어 사회적 단절과 이념적 양극화라는 구조적 결과로 연결되는 것이다.
결국, 선택적 노출은 인간의 성향에서 비롯되더라도, 알고리즘은 이를 사회 전반의 구조적 메커니즘으로 전환시키는 결정적 매개체이다. 따라서 양극화의 심화는 단순한 선택의 자유가 아니라, 알고리즘이라는 기술적 설계와 경제적 동기가 결합된 정보 환경의 산물로 이해되어야 한다. 알고리즘은 선택의 자유를 보장하는 기술이 아니라, 오히려 선택의 범위를 은밀히 제한하고, 반대 의견에 대한 접촉 가능성을 체계적으로 차단하며, 이념적 고립을 심화시키는 메커니즘으로 기능한다. 이로써 알고리즘은 인간의 선택적 노출 경향을 단순히 반영하는 것이 아니라, 이를 구조화하고 강화하여 정치적 양극화를 가속화하는 결정적 역할을 수행한다.

## 결론

본 논문은 인터넷의 알고리즘 기반 정보 추천 시스템이 정치적 양극화를 심화시키는 구조적 메커니즘으로 기능한다는 점을 논증하였다. 이를 위해 알고리즘의 선택적 노출 메커니즘, 사용자의 선택적 노출 경향과 반대 의견 회피의 상관관계, 그리고 알고리즘-선택성 상호작용 구조가 만들어내는 정보 환경 왜곡 효과를 단계적으로 살펴보았다. 먼저, 알고리즘은 사용자의 클릭, 선호, 반응을 실시간으로 분석하여 유사한 정보만을 반복적으로 제공함으로써 정보의 다양성을 구조적으로 차단하고 필터 버블을 형성한다. 이 과정에서 알고리즘은 단순히 사용자의 선택을 반영하는 도구가 아니라, 선택의 범위를 은밀히 제한하고 반대 의견에 대한 노출 기회를 원천적으로 차단하는 기술적 메커니즘으로 작동한다. 또한, 사용자의 선택적 노출 경향은 알고리즘과 결합되며 반대 의견 회피를 강화한다. 이는 단순히 선호에 따른 정보 선택이 아닌, 반대 의견에 대한 정서적 적대감과 회피 행동으로 구체화되며, 이념적 고립을 심화시키는 방향으로 작동한다. 마지막으로, 이러한 알고리즘-선택성 구조는 허위 정보와 감정적 콘텐츠의 확산을 가속화하여, 사회적 분열과 정당 간 적대감을 증폭시키며, 정치적 양극화를 구조적으로 촉진한다.
이러한 분석을 통해 본 논문은 기존의 선택적 노출 논의에서 '선택은 개인의 자유'라는 자유주의적 전제를 비판적으로 검토하고, 알고리즘이 그 자유를 실질적으로 구조화하고 제한하는 방식을 구체적으로 드러냈다. 특히 기존 연구들이 선택적 노출 경향을 인간의 인지적 습성과 오프라인 미디어 환경의 한계로 환원시키는 경향을 보였던 데 비해, 본 논문은 알고리즘의 설계 구조, 실시간 데이터 처리 방식, 감정적 콘텐츠 우선 노출, 피드백 루프 형성이라는 구체적 메커니즘을 분석함으로써 알고리즘의 고유한 역할과 그 파급력을 드러냈다. 이로써 '인간은 원래 선택적 노출을 한다'는 보편적 설명에 의존해 기술의 역할을 간과해온 기존 논의의 한계를 비판적으로 조명하고, 알고리즘이 선택적 노출 경향을 질적·속도적으로 증폭하며 집단 차원의 양극화를 심화시키는 결정적 기제로 기능한다는 점을 새롭게 밝혔다.
그러나 본 논문은 인터넷 알고리즘이 항상 동일한 방식으로 양극화를 촉진한다고 주장하지 않는다. 알고리즘 설계 방식과 사용자 집단의 특성, 사회적 맥락에 따라 그 영향은 달라질 수 있으며, 이를 종합적으로 분석하는 추가 연구가 필요함을 강조한다. 그럼에도 불구하고, 현재의 주류 알고리즘 설계—특히 클릭과 체류시간 중심의 상업적 최적화 방식—은 분명히 양극화를 심화시키는 방향으로 작동하는 경향이 강하며, 이는 단순한 선택의 자유로 설명될 수 없는 구조적 문제라는 점을 본 논문은 강조한다.
따라서 알고리즘 기반 정보 환경은 개인의 선택적 노출 경향을 단순히 반영하는 것이 아니라, 이를 가속화하고 구조화하며, 나아가 정치적 양극화를 심화시키는 기술적 메커니즘으로 기능한다. 이로써 본 논문은 인터넷과 알고리즘, 그리고 정치적 양극화의 관계에 대한 기존 논의를 재조명하며, 알고리즘의 사회적 책임성과 설계 방식에 대한 비판적 논의를 촉진하는 데 기여하고자 한다.

## 참고문헌

> Bail, Christopher A. et al. (2018). “Exposure to Opposing Views on Social Media Can Increase Political Polarization.” Proceedings of the National Academy of Sciences - PNAS, 115(37), 9216–9221. Web.
>
> Boxell, L., Gentzkow, M., & Shapiro, J. M. (2017). Greater internet use is not associated with faster growth in political polarization among US demographic groups. Proceedings of the National Academy of Sciences.
>
> Gentzkow, M., & Shapiro, J. M. (2011). Ideological segregation online and offline. Quarterly Journal of Economics, 126(4), 1799–1839.
>
> Pariser, E. (2011). The filter bubble: What the Internet is hiding from you. The Penguin Press.
>
> Piccardi, T., Saveski, M., Jia, C., Hancock, J. T., Tsai, J. L., & Bernstein, M. (2024). Social media algorithms can shape affective polarization via exposure to antidemocratic attitudes and partisan animosity. arXiv preprint arXiv:2411.14652. https://doi.org/10.48550/arXiv.2411.14652
>
> Spohr, D. (2017). Fake news and ideological polarization: Filter bubbles and selective exposure on social media. Media, Culture & Society, 39(3), 411–428.
>
> Tucker, J. A., Guess, A. M., Barberá, P., Vaccari, C., Siegel, A., Sanovich, S., Stukal, D., & Nyhan, B. (2018). Social media, political polarization, and political disinformation: A review of the scientific literature. SSRN. https://doi.org/10.2139/ssrn.3144139
